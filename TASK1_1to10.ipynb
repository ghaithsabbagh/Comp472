{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e80204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture cap \n",
    "\n",
    "import sklearn \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report #7c\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "corpus = load_files('BBC_dataset\\BBC', encoding='latin1', load_content=True)\n",
    "corpus.target_names\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(corpus.data, corpus.target, test_size=0.2, random_state=None)\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "matrix1 = vectorizer.fit_transform(X_train)\n",
    "matrix2 = vectorizer.transform(X_test)\n",
    "\n",
    "Tokens1 = matrix1.toarray() #transform the training set matrix to an ndarray\n",
    "Tokens2 = matrix2.toarray()  #transform the test set matrix to array\n",
    "\n",
    "row_sum1 = np.sum(Tokens1, axis=1) # gets the sum of rows for Tokens1 \n",
    "row_sum2 = np.sum(Tokens2, axis=1)   #Gets the sum of rows for Tokens2\n",
    "\n",
    "sumsArray1 = np.zeros(5, dtype = int) # To hold the result for training set \n",
    "sumsArray2 = np.zeros(5, dtype = int) # To hold the result for test set\n",
    "\n",
    "for i in range((len(row_sum1))):\n",
    "    index = Y_train[i]\n",
    "    sumsArray1[index] += row_sum1[i]\n",
    "    \n",
    "for i in range((len(row_sum2))):\n",
    "    index = Y_test[i]\n",
    "    sumsArray2[index] += row_sum2[i]\n",
    "\n",
    "#print(matrix1.toarray()) #prints non-zero elements\n",
    "\n",
    "# tokens_array = fitObject.toarray()\n",
    "# tokens_array2 = fitObject_.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1753971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR Question 7.g\n",
    "#print(tokens_array)\n",
    "counter = 0\n",
    "counter0 = 0\n",
    "for i,j in np.ndindex(Tokens1.shape):\n",
    "    counter += 1\n",
    "    if Tokens1[i,j] == 0:\n",
    "        counter0 += 1\n",
    "\n",
    "counter_x = 0\n",
    "counter_y = 0\n",
    "counter1_ = 0\n",
    "counter1 = 0\n",
    "\n",
    "for i,j in np.ndindex(Tokens1.shape):\n",
    "    counter_x += 1\n",
    "    if Tokens1[i,j] == 1:\n",
    "        counter1_ += 1\n",
    "\n",
    "for i,j in np.ndindex(Tokens2.shape):\n",
    "    counter_y += 1\n",
    "    if Tokens2[i,j] == 1:\n",
    "        counter1 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45932ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnNB = MultinomialNB() # Instantiating a Multinomial Bayes for the training set\n",
    "mnNB.fit(matrix1, Y_train)\n",
    "\n",
    "mnNB_ = MultinomialNB() # Instantiating a Multinomial Bayes for test set(needed for 7.g)\n",
    "mnNB_.fit(matrix2, Y_test)\n",
    "    \n",
    "#My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running #print(vectorizer.vocabulary_))\n",
    "\n",
    "logprob_arr = mnNB.feature_log_prob_\n",
    "#print(logprob_arr) # displays log(prob) for all features(words)\n",
    "\n",
    "eminem_arr = logprob_arr[:, 4621] #isolate column 4621 associated with log-prob of eminem and Store it \n",
    "tennis_arr = logprob_arr[:, 12841] #isolate column 12841 associated with log-prob of tennis and Store it \n",
    "\n",
    "class_prob_eminem = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class \n",
    "class_prob_tennis = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class\n",
    "\n",
    "for i in range((len(eminem_arr))):\n",
    "    index = Y_train[i]\n",
    "    class_prob_eminem[index] += eminem_arr[i]\n",
    "    \n",
    "for j in range((len(tennis_arr))):\n",
    "    index = Y_train[j]\n",
    "    class_prob_tennis[index] += tennis_arr[j]\n",
    "\n",
    "classPredict = mnNB.predict(matrix2) #Running classifier on the test set\n",
    "#--------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cf6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture cap\n",
    "print('Question 7')\n",
    "print('MultinomialNB Default values try 1', '\\n')\n",
    "print('(b)')\n",
    "\n",
    "ConfusionMatrix = metrics.confusion_matrix(Y_test, classPredict)\n",
    "print('Confusion Matrix: ')\n",
    "print(ConfusionMatrix, '\\n')\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "print('(c)')\n",
    "target_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('\\n', 'Classification Report')\n",
    "print(classification_report(Y_test, classPredict, target_names=target_names))\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "print('\\n', '(d)')\n",
    "Accuracy = metrics.accuracy_score(Y_test, classPredict)\n",
    "MacroF1score = f1_score(Y_test, classPredict, average='macro')\n",
    "WeightedF1score = f1_score(Y_test, classPredict, average='weighted')\n",
    "print('Accuracy = ', Accuracy)\n",
    "print('MacroF1score = ', MacroF1score)\n",
    "print('WeightedF1score = ', WeightedF1score)\n",
    "print('-------------------------------------------------------------')\n",
    "print('(e)')\n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('Prior probabilities: ')\n",
    "prior_log = (mnNB.class_log_prior_)\n",
    "prior = np.exp(prior_log)\n",
    "print(prior)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(f)')\n",
    "print('Size of the vocabulary(for training set) is the number of columns: ', matrix1.shape)\n",
    "print('**Another way to get the size of vocabulary**',mnNB.n_features_in_)  # Also gives the size of vocabulary\n",
    "print('-------------------------------------------------------------')\n",
    "print('(g)')\n",
    "print('Number of word tokens for each class in the training set: ', sumsArray1)\n",
    "print('Number of word tokens for each class in the test set: ',sumsArray2)  \n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!')\n",
    "print(mnNB.class_count_, 'Number of docs/class for training set')\n",
    "print(mnNB_.class_count_, 'Number of docs/class for test set')\n",
    "print(np.add(mnNB.class_count_, mnNB_.class_count_), 'Total number of docs for each class')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(h)')\n",
    "corpusTokens = np.add(sumsArray1, sumsArray2)   \n",
    "print('Number of tokens in the entire corpus for each class', corpusTokens)\n",
    "print('Number of tokens in the entire corpus', np.sum(corpusTokens, axis=0))\n",
    "print('-------------------------------------------------------------')\n",
    "print('(i)')\n",
    "print('Number of words with a frequency of zero in trainning set: ', counter0)\n",
    "print('Percentage of words with a frequency of zero in trainning set:', (counter0/counter)*100, '%')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(j)')\n",
    "print('Number of words with a frequency of one in the entire corpus: ', counter1_ + counter1 )\n",
    "print('Percentage of words with a frequency of one in the entire corpus:', ((counter1_ + counter1)/(counter_x + counter_y)*100), '%')    \n",
    "print('-------------------------------------------------------------')\n",
    "print('(k)')\n",
    "print('My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)')\n",
    "print('eminem', 'Log-prob: ', eminem_arr)\n",
    "print('tennis', 'Log-prob: ', tennis_arr)\n",
    "print('-------------------------------------------------------------')\n",
    "# with open('bbc-performance.txt', 'w') as out:\n",
    "#     out.write(cap.stdout)\n",
    "#==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6869832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8, redoing steps 6, 7\n",
    "mnNB = MultinomialNB() # Instantiating a Multinomial Bayes for the training set\n",
    "mnNB.fit(matrix1, Y_train)\n",
    "\n",
    "mnNB_ = MultinomialNB() # Instantiating a Multinomial Bayes for test set(needed for 7.g)\n",
    "mnNB_.fit(matrix2, Y_test)\n",
    "    \n",
    "#My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running #print(vectorizer.vocabulary_))\n",
    "\n",
    "logprob_arr = mnNB.feature_log_prob_\n",
    "#print(logprob_arr) # displays log(prob) for all features(words)\n",
    "\n",
    "eminem_arr = logprob_arr[:, 4621] #isolate column 4621 associated with log-prob of eminem and Store it \n",
    "tennis_arr = logprob_arr[:, 12841] #isolate column 12841 associated with log-prob of tennis and Store it \n",
    "\n",
    "class_prob_eminem = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class \n",
    "class_prob_tennis = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class\n",
    "\n",
    "for i in range((len(eminem_arr))):\n",
    "    index = Y_train[i]\n",
    "    class_prob_eminem[index] += eminem_arr[i]\n",
    "    \n",
    "for j in range((len(tennis_arr))):\n",
    "    index = Y_train[j]\n",
    "    class_prob_tennis[index] += tennis_arr[j]\n",
    "\n",
    "classPredict = mnNB.predict(matrix2) #Running classifier on the test set\n",
    "#--------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9abecb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 8\n",
      "MultinomialNB Default values try 2 \n",
      "\n",
      "Step 7\n",
      "(b)\n",
      "Confusion Matrix: \n",
      "[[87  1  2  0  3]\n",
      " [ 0 84  2  0  0]\n",
      " [ 0  0 79  0  1]\n",
      " [ 0  0  1 96  0]\n",
      " [ 1  1  0  0 87]] \n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "(c)\n",
      "\n",
      " Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.99      0.94      0.96        93\n",
      "entertainment       0.98      0.98      0.98        86\n",
      "     politics       0.94      0.99      0.96        80\n",
      "        sport       1.00      0.99      0.99        97\n",
      "         tech       0.96      0.98      0.97        89\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      " (d)\n",
      "Accuracy =  0.9730337078651685\n",
      "MacroF1score =  0.9725940213120179\n",
      "WeightedF1score =  0.9730499512552644\n",
      "-------------------------------------------------------------\n",
      "(e)\n",
      "Class names:  ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "Prior probabilities: \n",
      "[0.23426966 0.16853933 0.18932584 0.23258427 0.1752809 ]\n",
      "-------------------------------------------------------------\n",
      "(f)\n",
      "Size of the vocabulary(for training set) is the number of columns:  (1780, 26977)\n",
      "**Another way to get the size of vocabulary** 26977\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Question 8')\n",
    "print('MultinomialNB Default values try 2', '\\n')\n",
    "print('Step 7')\n",
    "print('(b)')\n",
    "ConfusionMatrix = metrics.confusion_matrix(Y_test, classPredict)\n",
    "print('Confusion Matrix: ')\n",
    "print(ConfusionMatrix, '\\n')\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "print('(c)')\n",
    "target_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('\\n', 'Classification Report')\n",
    "print(classification_report(Y_test, classPredict, target_names=target_names))\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "print('\\n', '(d)')\n",
    "Accuracy = metrics.accuracy_score(Y_test, classPredict)\n",
    "MacroF1score = f1_score(Y_test, classPredict, average='macro')\n",
    "WeightedF1score = f1_score(Y_test, classPredict, average='weighted')\n",
    "\n",
    "print('Accuracy = ', Accuracy)\n",
    "print('MacroF1score = ', MacroF1score)\n",
    "print('WeightedF1score = ', WeightedF1score)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(e)')\n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('Prior probabilities: ')\n",
    "prior_log = (mnNB.class_log_prior_)\n",
    "prior = np.exp(prior_log)\n",
    "print(prior)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(f)')\n",
    "print('Size of the vocabulary(for training set) is the number of columns: ', matrix1.shape)\n",
    "print('**Another way to get the size of vocabulary**',mnNB.n_features_in_)  # Also gives the size of vocabulary\n",
    "print('-------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5569f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(g)\n",
      "Number of word tokens for each class in the training set:  [134055  98546 150559 134363 155383]\n",
      "Number of word tokens for each class in the test set:  [29889 25550 34085 28035 42478]\n",
      "Class names:  ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!\n",
      "[417. 300. 337. 414. 312.] Number of docs/class for training set\n",
      "[93. 86. 80. 97. 89.] Number of docs/class for test set\n",
      "[510. 386. 417. 511. 401.] Total number of docs for each class\n",
      "-------------------------------------------------------------\n",
      "(h)\n",
      "Number of tokens in the entire corpus for each class [163944 124096 184644 162398 197861]\n",
      "Number of tokens in the entire corpus 832943\n",
      "-------------------------------------------------------------\n",
      "(i)\n",
      "Number of words with a frequency of zero in trainning set:  47658364\n",
      "Percentage of words with a frequency of zero in trainning set: 99.24884826983286 %\n",
      "-------------------------------------------------------------\n",
      "(j)\n",
      "Number of words with a frequency of one in the entire corpus:  317562\n",
      "Percentage of words with a frequency of one in the entire corpus: 0.5290599191237813 %\n",
      "-------------------------------------------------------------\n",
      "(k)\n",
      "My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)\n",
      "eminem Log-prob:  [-21.01636594 -20.70864647 -21.1324686  -21.01866082 -11.95356568]\n",
      "tennis Log-prob:  [ -9.86010113 -20.70864647 -21.1324686  -21.01866082 -21.16400605]\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#%%capture cap\n",
    "print('(g)')\n",
    "print('Number of word tokens for each class in the training set: ', sumsArray1)\n",
    "print('Number of word tokens for each class in the test set: ',sumsArray2)  \n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!')\n",
    "print(mnNB.class_count_, 'Number of docs/class for training set')\n",
    "print(mnNB_.class_count_, 'Number of docs/class for test set')\n",
    "print(np.add(mnNB.class_count_, mnNB_.class_count_), 'Total number of docs for each class')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(h)')\n",
    "corpusTokens = np.add(sumsArray1, sumsArray2)   \n",
    "print('Number of tokens in the entire corpus for each class', corpusTokens)\n",
    "print('Number of tokens in the entire corpus', np.sum(corpusTokens, axis=0))\n",
    "print('-------------------------------------------------------------')\n",
    "print('(i)')\n",
    "print('Number of words with a frequency of zero in trainning set: ', counter0)\n",
    "print('Percentage of words with a frequency of zero in trainning set:', (counter0/counter)*100, '%')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(j)')\n",
    "print('Number of words with a frequency of one in the entire corpus: ', counter1_ + counter1 )\n",
    "print('Percentage of words with a frequency of one in the entire corpus:', ((counter1_ + counter1)/(counter_x + counter_y)*100), '%')    \n",
    "print('-------------------------------------------------------------')\n",
    "print('(k)')\n",
    "print('My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)')\n",
    "print('eminem', 'Log-prob: ', eminem_arr)\n",
    "print('tennis', 'Log-prob: ', tennis_arr)\n",
    "print('-------------------------------------------------------------')\n",
    "# with open('bbc-performance.txt', 'a') as out:\n",
    "#     out.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9336da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 9 with smoothing = 0.0001\n",
    "mnNB = MultinomialNB(alpha = 0.0001) # Instantiating a Multinomial Bayes for the training set\n",
    "mnNB.fit(matrix1, Y_train)\n",
    "\n",
    "mnNB_ = MultinomialNB(alpha = 0.0001) # Instantiating a Multinomial Bayes for test set(needed for 7.g)\n",
    "mnNB_.fit(matrix2, Y_test)\n",
    "    \n",
    "#My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running #print(vectorizer.vocabulary_))\n",
    "\n",
    "logprob_arr = mnNB.feature_log_prob_\n",
    "#print(logprob_arr) # displays log(prob) for all features(words)\n",
    "\n",
    "eminem_arr = logprob_arr[:, 4621] #isolate column 4621 associated with log-prob of eminem and Store it \n",
    "tennis_arr = logprob_arr[:, 12841] #isolate column 12841 associated with log-prob of tennis and Store it \n",
    "\n",
    "class_prob_eminem = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class \n",
    "class_prob_tennis = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class\n",
    "\n",
    "for i in range((len(eminem_arr))):\n",
    "    index = Y_train[i]\n",
    "    class_prob_eminem[index] += eminem_arr[i]\n",
    "    \n",
    "for j in range((len(tennis_arr))):\n",
    "    index = Y_train[j]\n",
    "    class_prob_tennis[index] += tennis_arr[j]\n",
    "\n",
    "classPredict = mnNB.predict(matrix2) #Running classifier on the test set\n",
    "#--------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f483360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 9\n",
      "MultinomialNB try 3 with smoothing value = 0.0001  \n",
      "\n",
      "Step 7\n",
      "(b)\n",
      "Confusion Matrix: \n",
      "[[87  1  2  0  3]\n",
      " [ 0 84  2  0  0]\n",
      " [ 0  0 79  0  1]\n",
      " [ 0  0  1 96  0]\n",
      " [ 1  1  0  0 87]] \n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "(c)\n",
      "\n",
      " Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.99      0.94      0.96        93\n",
      "entertainment       0.98      0.98      0.98        86\n",
      "     politics       0.94      0.99      0.96        80\n",
      "        sport       1.00      0.99      0.99        97\n",
      "         tech       0.96      0.98      0.97        89\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      " (d)\n",
      "Accuracy =  0.9730337078651685\n",
      "MacroF1score =  0.9725940213120179\n",
      "WeightedF1score =  0.9730499512552644\n",
      "-------------------------------------------------------------\n",
      "(e)\n",
      "Class names:  ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "Prior probabilities: \n",
      "[0.23426966 0.16853933 0.18932584 0.23258427 0.1752809 ]\n",
      "-------------------------------------------------------------\n",
      "(f)\n",
      "Size of the vocabulary(for training set) is the number of columns:  (1780, 26977)\n",
      "**Another way to get the size of vocabulary** 26977\n",
      "-------------------------------------------------------------\n",
      "(g)\n",
      "Number of word tokens for each class in the training set:  [134055  98546 150559 134363 155383]\n",
      "Number of word tokens for each class in the test set:  [29889 25550 34085 28035 42478]\n",
      "Class names:  ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!\n",
      "[417. 300. 337. 414. 312.] Number of docs/class for training set\n",
      "[93. 86. 80. 97. 89.] Number of docs/class for test set\n",
      "[510. 386. 417. 511. 401.] Total number of docs for each class\n",
      "-------------------------------------------------------------\n",
      "(h)\n",
      "Number of tokens in the entire corpus for each class [163944 124096 184644 162398 197861]\n",
      "Number of tokens in the entire corpus 832943\n",
      "-------------------------------------------------------------\n",
      "(i)\n",
      "Number of words with a frequency of zero in trainning set:  47658364\n",
      "Percentage of words with a frequency of zero in trainning set: 99.24884826983286 %\n",
      "-------------------------------------------------------------\n",
      "(j)\n",
      "Number of words with a frequency of one in the entire corpus:  317562\n",
      "Percentage of words with a frequency of one in the entire corpus: 0.5290599191237813 %\n",
      "-------------------------------------------------------------\n",
      "(k)\n",
      "My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)\n",
      "eminem Log-prob:  [-21.01636594 -20.70864647 -21.1324686  -21.01866082 -11.95356568]\n",
      "tennis Log-prob:  [ -9.86010113 -20.70864647 -21.1324686  -21.01866082 -21.16400605]\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#%%capture cap\n",
    "print('Question 9')\n",
    "print('MultinomialNB try 3 with smoothing value = 0.0001 ', '\\n')\n",
    "print('Step 7')\n",
    "print('(b)')\n",
    "ConfusionMatrix = metrics.confusion_matrix(Y_test, classPredict)\n",
    "print('Confusion Matrix: ')\n",
    "print(ConfusionMatrix, '\\n')\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "print('(c)')\n",
    "target_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('\\n', 'Classification Report')\n",
    "print(classification_report(Y_test, classPredict, target_names=target_names))\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "print('\\n', '(d)')\n",
    "Accuracy = metrics.accuracy_score(Y_test, classPredict)\n",
    "MacroF1score = f1_score(Y_test, classPredict, average='macro')\n",
    "WeightedF1score = f1_score(Y_test, classPredict, average='weighted')\n",
    "\n",
    "print('Accuracy = ', Accuracy)\n",
    "print('MacroF1score = ', MacroF1score)\n",
    "print('WeightedF1score = ', WeightedF1score)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(e)')\n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('Prior probabilities: ')\n",
    "prior_log = (mnNB.class_log_prior_)\n",
    "prior = np.exp(prior_log)\n",
    "print(prior)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(f)')\n",
    "print('Size of the vocabulary(for training set) is the number of columns: ', matrix1.shape)\n",
    "print('**Another way to get the size of vocabulary**',mnNB.n_features_in_)  # Also gives the size of vocabulary\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(g)')\n",
    "print('Number of word tokens for each class in the training set: ', sumsArray1)\n",
    "print('Number of word tokens for each class in the test set: ',sumsArray2)  \n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!')\n",
    "print(mnNB.class_count_, 'Number of docs/class for training set')\n",
    "print(mnNB_.class_count_, 'Number of docs/class for test set')\n",
    "print(np.add(mnNB.class_count_, mnNB_.class_count_), 'Total number of docs for each class')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(h)')\n",
    "corpusTokens = np.add(sumsArray1, sumsArray2)   \n",
    "print('Number of tokens in the entire corpus for each class', corpusTokens)\n",
    "print('Number of tokens in the entire corpus', np.sum(corpusTokens, axis=0))\n",
    "print('-------------------------------------------------------------')\n",
    "print('(i)')\n",
    "print('Number of words with a frequency of zero in trainning set: ', counter0)\n",
    "print('Percentage of words with a frequency of zero in trainning set:', (counter0/counter)*100, '%')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(j)')\n",
    "print('Number of words with a frequency of one in the entire corpus: ', counter1_ + counter1 )\n",
    "print('Percentage of words with a frequency of one in the entire corpus:', ((counter1_ + counter1)/(counter_x + counter_y)*100), '%')    \n",
    "print('-------------------------------------------------------------')\n",
    "print('(k)')\n",
    "print('My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)')\n",
    "print('eminem', 'Log-prob: ', eminem_arr)\n",
    "print('tennis', 'Log-prob: ', tennis_arr)\n",
    "print('-------------------------------------------------------------')\n",
    "# with open('bbc-performance.txt', 'a') as out:\n",
    "#     out.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e018bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 10 with smoothing = 0.9\n",
    "mnNB = MultinomialNB(alpha = 0.9) # Instantiating a Multinomial Bayes for the training set\n",
    "mnNB.fit(matrix1, Y_train)\n",
    "\n",
    "mnNB_ = MultinomialNB(alpha = 0.9) # Instantiating a Multinomial Bayes for test set(needed for 7.g)\n",
    "mnNB_.fit(matrix2, Y_test)\n",
    "    \n",
    "#My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running #print(vectorizer.vocabulary_))\n",
    "\n",
    "logprob_arr = mnNB.feature_log_prob_\n",
    "#print(logprob_arr) # displays log(prob) for all features(words)\n",
    "\n",
    "eminem_arr = logprob_arr[:, 4621] #isolate column 4621 associated with log-prob of eminem and Store it \n",
    "tennis_arr = logprob_arr[:, 12841] #isolate column 12841 associated with log-prob of tennis and Store it \n",
    "\n",
    "class_prob_eminem = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class \n",
    "class_prob_tennis = np.zeros(5, dtype = int) # To hold the result for sum of log-probs for each class\n",
    "\n",
    "for i in range((len(eminem_arr))):\n",
    "    index = Y_train[i]\n",
    "    class_prob_eminem[index] += eminem_arr[i]\n",
    "    \n",
    "for j in range((len(tennis_arr))):\n",
    "    index = Y_train[j]\n",
    "    class_prob_tennis[index] += tennis_arr[j]\n",
    "\n",
    "classPredict = mnNB.predict(matrix2) #Running classifier on the test set\n",
    "#--------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d95c75d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 10\n",
      "MultinomialNB try 4 with smoothing value = 0.9  \n",
      "\n",
      "Step 7\n",
      "(b)\n",
      "Confusion Matrix: \n",
      "[[89  0  2  0  2]\n",
      " [ 0 84  1  0  1]\n",
      " [ 1  0 78  0  1]\n",
      " [ 0  0  1 96  0]\n",
      " [ 0  1  0  0 88]] \n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "(c)\n",
      "\n",
      " Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.99      0.96      0.97        93\n",
      "entertainment       0.99      0.98      0.98        86\n",
      "     politics       0.95      0.97      0.96        80\n",
      "        sport       1.00      0.99      0.99        97\n",
      "         tech       0.96      0.99      0.97        89\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      " (d)\n",
      "Accuracy =  0.9775280898876404\n",
      "MacroF1score =  0.9770582084799463\n",
      "WeightedF1score =  0.9775868029015019\n",
      "-------------------------------------------------------------\n",
      "(e)\n",
      "Class names:  ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "Prior probabilities: \n",
      "[0.23426966 0.16853933 0.18932584 0.23258427 0.1752809 ]\n",
      "-------------------------------------------------------------\n",
      "(f)\n",
      "Size of the vocabulary(for training set) is the number of columns:  (1780, 26977)\n",
      "**Another way to get the size of vocabulary** 26977\n",
      "-------------------------------------------------------------\n",
      "(g)\n",
      "Number of word tokens for each class in the training set:  [134055  98546 150559 134363 155383]\n",
      "Number of word tokens for each class in the test set:  [29889 25550 34085 28035 42478]\n",
      "Class names:  ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!\n",
      "[417. 300. 337. 414. 312.] Number of docs/class for training set\n",
      "[93. 86. 80. 97. 89.] Number of docs/class for test set\n",
      "[510. 386. 417. 511. 401.] Total number of docs for each class\n",
      "-------------------------------------------------------------\n",
      "(h)\n",
      "Number of tokens in the entire corpus for each class [163944 124096 184644 162398 197861]\n",
      "Number of tokens in the entire corpus 832943\n",
      "-------------------------------------------------------------\n",
      "(i)\n",
      "Number of words with a frequency of zero in trainning set:  47658364\n",
      "Percentage of words with a frequency of zero in trainning set: 99.24884826983286 %\n",
      "-------------------------------------------------------------\n",
      "(j)\n",
      "Number of words with a frequency of one in the entire corpus:  317562\n",
      "Percentage of words with a frequency of one in the entire corpus: 0.5290599191237813 %\n",
      "-------------------------------------------------------------\n",
      "(k)\n",
      "My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)\n",
      "eminem Log-prob:  [-12.07782442 -11.82387882 -12.17697734 -12.07976778 -11.45698037]\n",
      "tennis Log-prob:  [ -9.90560114 -11.82387882 -12.17697734 -12.07976778 -12.20419477]\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Question 10')\n",
    "print('MultinomialNB try 4 with smoothing value = 0.9 ', '\\n')\n",
    "print('Step 7')\n",
    "print('(b)')\n",
    "ConfusionMatrix = metrics.confusion_matrix(Y_test, classPredict)\n",
    "print('Confusion Matrix: ')\n",
    "print(ConfusionMatrix, '\\n')\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "print('(c)')\n",
    "target_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('\\n', 'Classification Report')\n",
    "print(classification_report(Y_test, classPredict, target_names=target_names))\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "print('\\n', '(d)')\n",
    "Accuracy = metrics.accuracy_score(Y_test, classPredict)\n",
    "MacroF1score = f1_score(Y_test, classPredict, average='macro')\n",
    "WeightedF1score = f1_score(Y_test, classPredict, average='weighted')\n",
    "\n",
    "print('Accuracy = ', Accuracy)\n",
    "print('MacroF1score = ', MacroF1score)\n",
    "print('WeightedF1score = ', WeightedF1score)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(e)')\n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('Prior probabilities: ')\n",
    "prior_log = (mnNB.class_log_prior_)\n",
    "prior = np.exp(prior_log)\n",
    "print(prior)\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(f)')\n",
    "print('Size of the vocabulary(for training set) is the number of columns: ', matrix1.shape)\n",
    "print('**Another way to get the size of vocabulary**',mnNB.n_features_in_)  # Also gives the size of vocabulary\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "print('(g)')\n",
    "print('Number of word tokens for each class in the training set: ', sumsArray1)\n",
    "print('Number of word tokens for each class in the test set: ',sumsArray2)  \n",
    "class_names = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "print('Class names: ', class_names)\n",
    "print('NB: The MultinomialNB attribute class_count_ generates the number of documents for each class which is not what we are looking for!')\n",
    "print(mnNB.class_count_, 'Number of docs/class for training set')\n",
    "print(mnNB_.class_count_, 'Number of docs/class for test set')\n",
    "print(np.add(mnNB.class_count_, mnNB_.class_count_), 'Total number of docs for each class')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(h)')\n",
    "corpusTokens = np.add(sumsArray1, sumsArray2)   \n",
    "print('Number of tokens in the entire corpus for each class', corpusTokens)\n",
    "print('Number of tokens in the entire corpus', np.sum(corpusTokens, axis=0))\n",
    "print('-------------------------------------------------------------')\n",
    "print('(i)')\n",
    "print('Number of words with a frequency of zero in trainning set: ', counter0)\n",
    "print('Percentage of words with a frequency of zero in trainning set:', (counter0/counter)*100, '%')\n",
    "print('-------------------------------------------------------------')\n",
    "print('(j)')\n",
    "print('Number of words with a frequency of one in the entire corpus: ', counter1_ + counter1 )\n",
    "print('Percentage of words with a frequency of one in the entire corpus:', ((counter1_ + counter1)/(counter_x + counter_y)*100), '%')    \n",
    "print('-------------------------------------------------------------')\n",
    "print('(k)')\n",
    "print('My 2 FAV words with their indices: eminem: 4621 ; tennis: 12841 (retrieved by running vectorizer.vocabulary_)')\n",
    "print('eminem', 'Log-prob: ', eminem_arr)\n",
    "print('tennis', 'Log-prob: ', tennis_arr)\n",
    "print('-------------------------------------------------------------')\n",
    "# with open('bbc-performance.txt', 'a') as out:\n",
    "#     out.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d350d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
